# backend/Dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create non-root user
RUN groupadd -r appuser && useradd -r -g appuser appuser
RUN chown -R appuser:appuser /app
USER appuser

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8000/health')"

# Run the application
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]

# frontend/Dockerfile
FROM node:18-alpine

WORKDIR /app

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm ci --only=production

# Copy source code
COPY . .

# Build the application
RUN npm run build

# Install serve to run the built app
RUN npm install -g serve

# Create non-root user
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nextjs -u 1001
USER nextjs

# Expose port
EXPOSE 3000

# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:3000/ || exit 1

# Serve the built application
CMD ["serve", "-s", "dist", "-l", "3000"]

# docker-compose.yml
version: '3.8'

services:
  backend:
    build: 
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - GROQ_API_KEY=${GROQ_API_KEY}
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis
    volumes:
      - ./backend:/app
    networks:
      - app-network
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    depends_on:
      - backend
    networks:
      - app-network
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - app-network
    restart: unless-stopped
    command: redis-server --appendonly yes

networks:
  app-network:
    driver: bridge

volumes:
  redis_data:

# .env.example
# Copy this file to .env and fill in your actual values

# Groq API Configuration
GROQ_API_KEY=your_groq_api_key_here

# Model Configuration
MODEL_NAME=mixtral-8x7b-32768
TEMPERATURE=0.3
MAX_AGENT_CALLS=5

# Redis Configuration (for future use)
REDIS_URL=redis://localhost:6379

# Development Configuration
NODE_ENV=development

# .gitignore
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
pip-wheel-metadata/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDEs
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Node.js
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*
lerna-debug.log*
.pnpm-debug.log*

# Runtime data
pids
*.pid
*.seed
*.pid.lock

# Coverage directory used by tools like istanbul
coverage/
*.lcov

# Build outputs
dist/
build/

# Docker
.dockerignore

# Logs
logs
*.log

# Database
*.db
*.sqlite

# README.md
# Multi-Agent Arithmetic System

A sophisticated multi-agent system built with LangGraph, FastAPI, and React that performs mathematical calculations using specialized sub-agents.

## Features

- **Meta-Agent Coordination**: Intelligent routing and orchestration of sub-agents
- **Specialized Sub-Agents**: Dedicated agents for addition, subtraction, multiplication, and division
- **React Prompting**: Advanced reasoning capabilities using React (Reasoning + Acting) methodology
- **Conversation Memory**: Client-side conversation history management
- **Real-time Processing**: Fast and efficient calculation processing
- **Dockerized Deployment**: Complete containerization for easy deployment

## Architecture

### Backend (FastAPI + LangGraph)
- **Meta-Agent**: Orchestrates the entire calculation process using LangGraph StateGraph
- **Sub-Agents**: Four specialized agents for arithmetic operations
- **LLM Service**: Groq-powered reasoning and natural language processing
- **Structured I/O**: JSON-based communication using Instructor SDK

### Frontend (React)
- **Chat Interface**: User-friendly conversation interface
- **History Management**: Local storage of conversation history
- **Real-time Status**: Connection status and processing indicators
- **Responsive Design**: Modern, accessible UI with Tailwind CSS

## Quick Start

### Prerequisites
- Docker and Docker Compose
- Groq API key

### Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd multi-agent-arithmetic
   ```

2. **Set up environment variables**
   ```bash
   cp .env.example .env
   # Edit .env and add your GROQ_API_KEY
   ```

3. **Run with Docker Compose**
   ```bash
   docker-compose up --build
   ```

4. **Access the application**
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

### Development Setup

#### Backend
```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
uvicorn app.main:app --reload
```

#### Frontend
```bash
cd frontend
npm install
npm run dev
```

## Usage Examples

- "What's 5 + 3?"
- "Calculate (10 - 4) * 2"
- "Divide 20 by 4"
- "What's 15 + 7 - 3 * 2?"

## System Design

### LangGraph StateGraph Structure
```
Entry Point: reasoning
    ↓
reasoning → execute_operations → generate_response → END
```

### Agent Coordination
1. **Reasoning Node**: Meta-agent analyzes user input using React prompting
2. **Execution Node**: Sub-agents perform arithmetic operations in correct order
3. **Response Node**: Natural language response generation

### Key Features
- **Maximum Call Limits**: Prevents infinite loops and excessive processing
- **Order of Operations**: Proper mathematical precedence (PEMDAS/BODMAS)
- **Error Handling**: Graceful handling of invalid inputs and edge cases
- **Structured Output**: Consistent JSON-based agent communication

## Configuration

### LLM Settings
- **Model**: mixtral-8x7b-32768 (Groq)
- **Temperature**: 0.3 (balanced reasoning and creativity)
- **Max Agent Calls**: 5 (prevents excessive processing)

### Future Extensibility
The system is designed to be easily extended with:
- **Memory Systems**: Long-term and short-term memory storage
- **Database Integration**: Persistent storage capabilities
- **Advanced Agents**: Web search, document RAG, API calls, CRUD operations
- **Multi-modal Support**: Image and document processing

## API Endpoints

### POST /chat
Process a mathematical query
```json
{
  "message": "What's 5 + 3?",
  "conversation_id": "optional"
}
```

### GET /health
Service health check

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## License

MIT License

## Troubleshooting

### Common Issues

1. **Groq API Key Issues**
   - Ensure your GROQ_API_KEY is set correctly in .env
   - Check API key validity and rate limits

2. **Docker Issues**
   - Ensure Docker and Docker Compose are installed
   - Check port availability (3000, 8000, 6379)

3. **Connection Issues**
   - Verify backend is running on port 8000
   - Check CORS configuration for frontend-backend communication

### Debug Mode
Set environment variable `DEBUG=true` for detailed logging.

## Performance Considerations

- **Agent Call Limits**: Configurable maximum to prevent runaway processes
- **Response Caching**: Redis integration for future performance optimization
- **Lightweight Operations**: Efficient arithmetic operations with minimal overhead
- **Error Recovery**: Graceful degradation and error handling